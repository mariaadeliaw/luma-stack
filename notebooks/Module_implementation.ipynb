{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "17b9b0c0",
   "metadata": {},
   "source": [
    "# Demonstration of Luma Module \n",
    "This notebook contain the implementation of the source code for each module in the EPISTEM land cover mapping framework"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed875980",
   "metadata": {},
   "source": [
    "## Library import and earth engine initialization\n",
    "If you have earth engine account you could used that to authenticate and initialize the earth engine. However, if you did not have the account, service account initialization is avaliable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1be9d7e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.2 -> 25.3\n",
      "[notice] To update, run: C:\\Users\\AFahrezi\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "#This code is used if the notebook is implemented in github codespace. Just remove the (#)\n",
    "!python -m pip install .. --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d131ed9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    EARTH ENGINE AUTHENTICATION NOTES:\n",
      "    \n",
      "    1. Make sure you already have a google cloud project that has enable the Earth Engine API and registered to \n",
      "       commercial or non-commercial use. For more information visit: https://developers.google.com/earth-engine/guides/access \n",
      "    \n",
      "    2. you can authenticate programmatically by calling: from luma_ge.ee_config import authenticate_manually\n",
      "       authenticate_manually()\n",
      "    \n",
      "    3. This will open a web browser. Sign in with your Google account that has Earth Engine access.\n",
      "    \n",
      "    4. Copy the authorization code from the browser and paste it in the terminal.\n",
      "    \n",
      "    \n",
      "    For more details, visit: https://developers.google.com/earth-engine/guides/python_install\n",
      "    \n",
      "Earth Engine initialized with service account successfully!\n",
      "Initialized: True\n",
      "Authenticated: True\n"
     ]
    }
   ],
   "source": [
    "import ee \n",
    "import luma_ge\n",
    "\n",
    "#Option 1: Manual authenticate using personal account\n",
    "#Instructions for manual authentication\n",
    "luma_ge.print_auth_instructions()\n",
    "#uncomment the below line and follow earth engine authentication process\n",
    "#luma_ge.authenticate_manually()\n",
    "\n",
    "#Option 2: Autheticate using service account (json file)\n",
    "service_account_path = '../auth/earth-engine-451407-520c1ef64879.json' #(if failed use this)\n",
    "#service_account_path = '../auth/ee-epstm2024.json'\n",
    "success = luma_ge.initialize_with_service_account(service_account_path)\n",
    "\n",
    "if success:\n",
    "    print(\"Earth Engine initialized with service account successfully!\")\n",
    "else:\n",
    "    print(\"Service account initialization failed. Try to authenticate earth engine manually\")\n",
    "\n",
    "#Check authentication status\n",
    "status = luma_ge.get_auth_status()\n",
    "print(f\"Initialized: {status['initialized']}\")\n",
    "print(f\"Authenticated: {status['authenticated']}\")\n",
    "if status['project']:\n",
    "    print(f\"Project: {status['project']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "87e17a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geemap\n",
    "from luma_ge.data_acquisition import Reflectance_Data, Reflectance_Stats, final_Image\n",
    "from luma_ge.helpers import get_aoi_from_gaul"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77a1466e",
   "metadata": {},
   "source": [
    "## Module 1: Acquisition of Near-Cloud-Free Satellite Imagery"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5114ef38",
   "metadata": {},
   "source": [
    "### System Response 1.1: Area of Interest Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d8507432",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Set the country and province for the AOI using GAUL admin boundaries\n",
    "aoi = get_aoi_from_gaul(country=\"Indonesia\", province=\"Sumatera Selatan\")\n",
    "#Alternatively, used geemap_shp_to_ee to directly used shapefile in your local machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9e11db3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              WADMKK\n",
      "0                   \n",
      "1                   \n",
      "2                   \n",
      "3                   \n",
      "4                   \n",
      "..               ...\n",
      "543          Boalemo\n",
      "544     Bone Bolango\n",
      "545         Pohuwato\n",
      "546  Gorontalo Utara\n",
      "547   Kota Gorontalo\n",
      "\n",
      "[548 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "#alternatively, you can also select smaller AOI using regency data below\n",
    "import pandas as pd\n",
    "indo_regency = ee.FeatureCollection('projects/ee-agilakbar/assets/Indonesian_Regency')\n",
    "#check Regency List\n",
    "regency = indo_regency.aggregate_array(\"WADMKK\").getInfo()\n",
    "print(pd.DataFrame(regency, columns=[\"WADMKK\"]))\n",
    "#province = indo_regency.aggregate_array(\"WADMPR\").getInfo()\n",
    "#Example for Pagar Alam\n",
    "regency_name = \"Kota Pagar Alam\"\n",
    "#Filter the FeatureCollection, used it for AOI\n",
    "single_aoi = indo_regency.filter(ee.Filter.eq(\"WADMKK\", regency_name)).geometry()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "186e3a9f",
   "metadata": {},
   "source": [
    "### System Response 1.2: Search and Filter Imagery\n",
    "The EPISTEM source code supports Landsat mission data, ranging from Landsat 1 to Landsat 9. For Landsat 1 - 3, the avaliable data is corrected radiance reflectance. The Landsat 5-9 used here is collection 2 surface reflectance (SR) analysis ready data.\n",
    "\n",
    "The retrival logic used here is as follow:\n",
    "1. Retrive multispectral bands (band 1 - 7) from landsat collection 2 SR data (if avaliable)\n",
    "2. Retrive thermal band from landsat collection 2 TOA data \n",
    "3. Create temporal composite for each data \n",
    "4. Stacked the final two data into a earth engine image (ee.image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3027fb75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-11 13:25:37,372 - Reflectance_Data - INFO - ReflectanceData initialized.\n",
      "2025-12-11 13:25:37,373 - final_Image - INFO - final_Image initialized.\n",
      "2025-12-11 13:25:37,373 - Reflectance_Data - INFO - Starting data fetch for Landsat 8 Operational Land Imager Surface Reflectance\n",
      "2025-12-11 13:25:37,374 - Reflectance_Data - INFO - Date range: 2017-01-01 to 2017-12-31\n",
      "2025-12-11 13:25:37,375 - Reflectance_Data - INFO - Cloud cover threshold: 40%\n",
      "2025-12-11 13:25:37,375 - Reflectance_Data - INFO - detailed statistics will not be computed\n",
      "2025-12-11 13:25:37,376 - Reflectance_Stats - INFO - Reflectance Stats initialized.\n",
      "2025-12-11 13:25:37,377 - Reflectance_Data - INFO - Filtered collection created (use compute_detailed_stats=True for more information)\n",
      "2025-12-11 13:25:38,115 - final_Image - INFO - Creating quality mosaic from 53 images using NDVI as quality metric\n",
      "2025-12-11 13:25:38,116 - final_Image - INFO - Quality mosaic created covering AOI with best available pixels\n",
      "2025-12-11 13:25:40,663 - final_Image - INFO - Mosaic date range: 2017-04-05 to 2017-12-17\n",
      "2025-12-11 13:25:41,481 - final_Image - INFO - Creating Median composite from 53 images\n",
      "2025-12-11 13:25:41,482 - final_Image - INFO - Composite clipped to AOI\n",
      "2025-12-11 13:25:43,814 - final_Image - INFO - Composite created from 2017-04-05 to 2017-12-17\n",
      "2025-12-11 13:25:43,814 - final_Image - INFO - Calculating data coverage within AOI...\n",
      "2025-12-11 13:25:47,306 - final_Image - INFO - Data coverage: 99.1% (85483.11 km² of 86281.90 km²)\n",
      "2025-12-11 13:25:47,306 - final_Image - INFO - Data gaps: 0.9% (798.79 km²)\n"
     ]
    }
   ],
   "source": [
    "#========== FIRST RETRIVE THE MULTISPECTRAL BAND===========\n",
    "#Intialize the relfectance class data function\n",
    "optical_reflectance = Reflectance_Data()\n",
    "#Initialize the final image class for composite creation\n",
    "composite = final_Image() #NEW FEATURE ADDED HERE\n",
    "#define the start and end date for imagery collection\n",
    "start = '2017-01-01'\n",
    "end = '2017-12-31'\n",
    "#get the image collection and corresponding statistics\n",
    "landsat_data, meta = optical_reflectance.get_optical_data(aoi, start, end, optical_data='L8_SR', \n",
    "                                                           cloud_cover=40, compute_detailed_stats=False)\n",
    "#create mosaic between image collection, and clip based on AOI\n",
    "mosaic_landsat = composite.get_quality_mosaic(landsat_data, aoi, quality_band= 'NDVI', calculate_coverage=False) #REPLACE OLD CODE WITH THE NEW ONE HERE\n",
    "#Alternatively you can use temporal aggregation (ee reducer) to create mode cloudless imagery\n",
    "#Add new functionality to calculate the coverage of the composite\n",
    "median_landsat, coverage = composite.get_temporal_composite(landsat_data, aoi, reducer='Median', calculate_coverage=True) #REPLACE OLD CODE WITH THE NEW ONE HERE\n",
    "#visualization parameter\n",
    "l8_sr_visparam = {'min': 0,'max': 0.4,'gamma': [0.95, 1.1, 1],'bands':['NIR', 'RED', 'GREEN']}\n",
    "#Add the data to the map\n",
    "Map = geemap.Map()\n",
    "Map.addLayer(mosaic_landsat, l8_sr_visparam, 'L8 SR Mosaic')\n",
    "Map.addLayer(median_landsat, l8_sr_visparam, 'L8 SR Median')\n",
    "Map.addLayer(landsat_data, l8_sr_visparam, 'L8 SR Image Collection')\n",
    "# set center of the map in the area of interest\n",
    "Map.centerObject(aoi, 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "62243459",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-11 13:26:41,966 - Reflectance_Stats - INFO - Reflectance Stats initialized.\n",
      "2025-12-11 13:26:41,968 - Reflectance_Data - INFO - Starting thermal data fetch for Landsat 8 Top-of-atmosphere reflectance\n",
      "2025-12-11 13:26:41,969 - Reflectance_Data - INFO - Date range: 2017-01-01 to 2017-12-31\n",
      "2025-12-11 13:26:41,970 - Reflectance_Data - INFO - Cloud cover threshold: 40%\n",
      "2025-12-11 13:26:41,970 - Reflectance_Data - INFO - Fast mode enabled - detailed statistics will not be computed\n",
      "2025-12-11 13:26:41,972 - Reflectance_Data - INFO - Filtered collection created (use compute_detailed_stats=True for detailed info)\n",
      "2025-12-11 13:26:42,698 - final_Image - INFO - Creating Median composite from 53 images\n",
      "2025-12-11 13:26:42,700 - final_Image - INFO - Composite clipped to AOI\n",
      "2025-12-11 13:26:44,638 - final_Image - INFO - Composite created from 2017-04-05 to 2017-12-17\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a66187c76581496a8a13106c2f6e5512",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map(center=[-3.2210694545062113, 104.16355582426587], controls=(WidgetControl(options=['position', 'transparen…"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#retive thermal bands from TOA\n",
    "thermal_bands, thermal_stats = optical_reflectance.get_thermal_bands(aoi, start, end, cloud_cover=40, compute_detailed_stats=False)\n",
    "median_thermal = composite.get_temporal_composite(thermal_bands, aoi, reducer='Median') #REPLACE THE OLD CODE WITH THE NEW ONE\n",
    "thermal_vis = {'min': 286,'max': 300,'gammma': 0.4}\n",
    "#stacked all landsat bands and convert to float(making sure all data type are compatible)\n",
    "stacked_landsat = median_landsat.addBands(median_thermal).toFloat()\n",
    "#visualize the thermal bands and multispectral bands\n",
    "Map.addLayer(median_thermal, thermal_vis, \"Thermal Bands\")\n",
    "Map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6d9542d",
   "metadata": {},
   "source": [
    "### Image retrival report (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5dcdcd22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-11 13:27:28,877 - Reflectance_Stats - INFO - Reflectance Stats initialized.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "           Landsat Data Collection Retrival Report\n",
      "============================================================\n",
      "Total Images Found: 53\n",
      "Date Range: 2017-01-13 to 2017-12-17\n",
      "Unique WRS Tiles: 10\n",
      "\n",
      "Scene Cloud Cover Statistics:\n",
      "------------------------------\n",
      "Average Cloud Cover: 26.8%\n",
      "Minimum Cloud Cover: 2.9%\n",
      "Maximum Cloud Cover: 40.0%\n",
      "\n",
      "WRS Path/Row Tiles:\n",
      "------------------------------\n",
      "Path 123/Row 062\n",
      "Path 123/Row 063\n",
      "Path 124/Row 061\n",
      "Path 124/Row 062\n",
      "Path 124/Row 063\n",
      "Path 124/Row 064\n",
      "Path 125/Row 061\n",
      "Path 125/Row 062\n",
      "Path 125/Row 063\n",
      "Path 126/Row 062\n",
      "\n",
      "Available Acqusition Date:\n",
      "------------------------------\n",
      "Date range: 2017-01-13 to 2017-12-17\n",
      "(53 total acquisition dates)\n",
      "\n",
      "Scene IDs (first 10):\n",
      "------------------------------\n",
      "• LC08_123062_20170405\n",
      "• LC08_123062_20170421\n",
      "• LC08_123062_20170726\n",
      "• LC08_123062_20170912\n",
      "• LC08_123062_20171014\n",
      "• LC08_123062_20171217\n",
      "• LC08_123063_20170710\n",
      "• LC08_123063_20170827\n",
      "• LC08_123063_20170912\n",
      "• LC08_123063_20171030\n",
      "... and 43 more scenes\n",
      "\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "#intialize the statistic class\n",
    "stats = Reflectance_Stats()\n",
    "#get the retrival report and automatically print them\n",
    "retrival_report = stats.get_collection_statistics(landsat_data, print_report=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb839e51",
   "metadata": {},
   "source": [
    "### System Response 1.3: Imagery Download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49d212e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "export_task = ee.batch.Export.image.toDrive(\n",
    "    image=stacked_landsat,\n",
    "    description='Landsat_Median_composite_2017_Sumsel',\n",
    "    folder='Earth Engine',\n",
    "    fileNamePrefix='Landsat_Median_composite_2017_Sumsel',\n",
    "    scale=30,\n",
    "    region=aoi,  # or aoi.geometry()\n",
    "    maxPixels=1e13\n",
    ")\n",
    "export_task.start()\n",
    "import time\n",
    "\n",
    "while export_task.active():\n",
    "    print('Exporting... (status: {})'.format(export_task.status()['state']))\n",
    "    time.sleep(10)\n",
    "\n",
    "print('Export complete (status: {})'.format(export_task.status()['state']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d798e32",
   "metadata": {},
   "source": [
    "## Module 2:  Land-cover classification Scheme\n",
    "Three approach are provided to handle classification scheme:\n",
    "1. Upload a csv file \n",
    "2. Manual input the classification scheme\n",
    "3. Use default classification scheme (RESTORE+ project)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e534c2be",
   "metadata": {},
   "source": [
    "### Import the module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2240e73f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from luma_ge.classification_scheme import LULC_Scheme_Manager\n",
    "#Initialize the LULC Scheme Manager\n",
    "manager = LULC_Scheme_Manager()\n",
    "print(\"Land Cover Classification Scheme Manager initialized!\")\n",
    "print(f\"Current class count: {manager.get_class_count()}\")\n",
    "#Temporary function to display the classiifcation scheme in notebook\n",
    "#Display current classification scheme\n",
    "def display_classification_scheme(manager):\n",
    "    \"\"\"Display the current classification scheme in a readable format\"\"\"\n",
    "    if not manager.has_classes():\n",
    "        print(\"No classes defined yet.\")\n",
    "        return\n",
    "    \n",
    "    print(\"\\n=== Current Classification Scheme ===\")\n",
    "    df = manager.get_dataframe()\n",
    "    print(df.to_string(index=False))\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Display the scheme\n",
    "df = display_classification_scheme(manager)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72d08dfb",
   "metadata": {},
   "source": [
    "### System Response 2.1a: Upload Classification Scheme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c972c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "#Reset manager for CSV upload example\n",
    "manager = LULC_Scheme_Manager()\n",
    "#path to csv \n",
    "csv_path = \"../data/Example_Classification_scheme.csv\"\n",
    "\n",
    "print(\"=== CSV Upload Process ===\")\n",
    "\n",
    "# Load the CSV\n",
    "df = pd.read_csv(csv_path, sep=None, engine=\"python\")\n",
    "print(\"Loaded CSV:\")\n",
    "print(df)\n",
    "\n",
    "# Auto-detect columns\n",
    "id_col, name_col, color_col = manager.auto_detect_csv_columns(df)\n",
    "print(f\"\\nAuto-detected columns:\")\n",
    "print(f\"ID column: {id_col}\")\n",
    "print(f\"Name column: {name_col}\")\n",
    "print(f\"Color column: {color_col}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dccbff10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process CSV upload\n",
    "success, message = manager.process_csv_upload(df, id_col, name_col, color_col)\n",
    "if success:\n",
    "    print(f\"✅ {message}\")\n",
    "    \n",
    "    # Finalize the upload\n",
    "    success, message = manager.finalize_csv_upload()\n",
    "    if success:\n",
    "        print(f\"✅ {message}\")\n",
    "    else:\n",
    "        print(f\"❌ {message}\")\n",
    "else:\n",
    "    print(f\"❌ {message}\")\n",
    "\n",
    "# Display the loaded scheme\n",
    "display_classification_scheme(manager)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa1d8b9f",
   "metadata": {},
   "source": [
    "### System Response 2.1b: Manual Scheme Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "458a8020",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reset manager for manual input example\n",
    "manager = LULC_Scheme_Manager()\n",
    "#Manually add the class\n",
    "print(\"=== Manual Class Addition ===\")\n",
    "\n",
    "#Example of class to add\n",
    "classes_to_add = [\n",
    "    (1, \"Hutan Lahan Kering\", \"#0E6D0E\"),\n",
    "    (2, \"Pertanian Lahan Kering\", \"#E8F800\"),\n",
    "    (3, \"Permukiman\", \"#F81D00\"),\n",
    "    (4, \"Badan Air\", \"#1512F3\"),\n",
    "    (5, \"Pertanian Lahan Basah\", \"#\")\n",
    "]\n",
    "\n",
    "for class_id, class_name, color_code in classes_to_add:\n",
    "    success, message = manager.add_class(class_id, class_name, color_code)\n",
    "    if success:\n",
    "        print(f\"✅ {message}\")\n",
    "    else:\n",
    "        print(f\"❌ {message}\")\n",
    "\n",
    "print(f\"\\nTotal classes: {manager.get_class_count()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "213558d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Edit an existing class\n",
    "print(\"=== Editing a Class ===\")\n",
    "\n",
    "# Edit the first class (index 0)\n",
    "class_to_edit = manager.edit_class(0)\n",
    "if class_to_edit:\n",
    "    print(f\"Editing class: {class_to_edit}\")\n",
    "    \n",
    "    # Update the class with new information\n",
    "    success, message = manager.add_class(1, \"HUtan Lahan Rendah\", \"#004D00\")\n",
    "    if success:\n",
    "        print(f\"✅ {message}\")\n",
    "    else:\n",
    "        print(f\"❌ {message}\")\n",
    "\n",
    "# Display updated scheme\n",
    "display_classification_scheme(manager)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "704bb924",
   "metadata": {},
   "source": [
    "### System Response 2.1c: Template Classification Scheme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11b2702d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset manager for default scheme example\n",
    "manager = LULC_Scheme_Manager()\n",
    "\n",
    "print(\"=== Available Default Schemes ===\")\n",
    "default_schemes = manager.get_default_schemes()\n",
    "\n",
    "for scheme_name, classes in default_schemes.items():\n",
    "    print(f\"\\n{scheme_name}: {len(classes)} classes\")\n",
    "    for class_data in classes:\n",
    "        print(f\"  - ID {class_data['ID']}: {class_data['Class Name']} ({class_data['Color Code']})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "982940ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the RESTORE+ default scheme\n",
    "scheme_name = \"RESTORE+ Project\"\n",
    "success, message = manager.load_default_scheme(scheme_name)\n",
    "\n",
    "if success:\n",
    "    print(f\"✅ {message}\")\n",
    "else:\n",
    "    print(f\"❌ {message}\")\n",
    "\n",
    "# Display the loaded scheme\n",
    "display_classification_scheme(manager)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdfc2278",
   "metadata": {},
   "source": [
    "### System Response 2.2: Download classification scheme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fecc7b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== Export Classification Scheme ===\")\n",
    "#Convert the selected  classification scheme manager to dataframe\n",
    "classification_df = manager.get_dataframe()\n",
    "print(\"Classification DataFrame:\")\n",
    "print(classification_df)\n",
    "#Save the file\n",
    "output_path = '../Selected_LC_Classification_Scheme.csv'\n",
    "classification_df.to_csv(output_path, index=False)\n",
    "print(f\"\\n✅ Classification scheme saved to: {output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "449588c3",
   "metadata": {},
   "source": [
    "# Module 3: Generate Region Of Interest\n",
    "Three methods to generate ROI are supported in EPISTEM platform:\n",
    "1. **Upload Training Data** - Upload your own shapefile\n",
    "2. **On-screen Sampling** - Create samples using interactive map\n",
    "3. **Default Reference Data** - Use Epistem's default training data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4acdddc0",
   "metadata": {},
   "source": [
    "## Library Import and Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2df1d02e",
   "metadata": {},
   "source": [
    "## System Response 3.1 Prerequisite Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d956b21d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== Checking Prerequisites ===\")\n",
    "#Load from previous module\n",
    "#From Module 1 - AOI data\n",
    "try:\n",
    "    AOI = aoi\n",
    "    print(\"✅ AOI from Module 1 is available\")\n",
    "    aoi_available = True\n",
    "except:\n",
    "    print(\"❌ AOI data not available, please run Module 1 first\")\n",
    "    aoi_available = False\n",
    "\n",
    "#From Module 2 - Classification scheme\n",
    "try:\n",
    "    \n",
    "    # For demonstration, create sample classification scheme\n",
    "    LULCTable = classification_df\n",
    "    print(\"✅ Classification scheme from Module 2 is available\")\n",
    "    print(f\"   - Number of classes: {len(LULCTable)}\")\n",
    "    scheme_available = True\n",
    "except:\n",
    "    print(\"❌ Classification scheme not available, please run Module 2 first\")\n",
    "    scheme_available = False\n",
    "\n",
    "if aoi_available and scheme_available:\n",
    "    print(\"\\n✅ All prerequisites met! You can proceed with training data collection.\")\n",
    "else:\n",
    "    print(\"\\n❌ Prerequisites not met. Please complete previous modules first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92cede0c",
   "metadata": {},
   "source": [
    "## System Response 3.2 ROI Upload and content Verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae398a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modul 3a \n",
    "# Import modules and functions\n",
    "import ee\n",
    "import pandas as pd\n",
    "from luma_ge.sample_data import SyncTrainData, SplitTrainData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7411b55c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----- Data Input -----\n",
    "# 1. Decision to upload data\n",
    "UploadTrainData = True # set as 'true' to upload your own training data shapefile\n",
    "# set as 'false' to either add train data by sampling on screen or use default training data\n",
    "\n",
    "# 2. Training data file path (if UploadTrainData is true)\n",
    "TrainVectPath  = '../data/Training_Sumsel_Data.shp'\n",
    "TrainField = 'ID' \n",
    "        # Load and process training data\n",
    "TrainDataDict = SyncTrainData.LoadTrainData(\n",
    "            landcover_df=LULCTable,\n",
    "            aoi_geometry=AOI,\n",
    "            training_shp_path=TrainVectPath\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f745ae9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----- System response 3.2.a -----\n",
    "# Set class field\n",
    "TrainDataDict = SyncTrainData.SetClassField(TrainDataDict, TrainField)\n",
    "\n",
    "# Validate classes\n",
    "TrainDataDict = SyncTrainData.ValidClass(TrainDataDict, 1)\n",
    "\n",
    "    # Check sample sufficiency\n",
    "TrainDataDict = SyncTrainData.CheckSufficiency(TrainDataDict, min_samples=20)\n",
    "\n",
    "    # Filter by AOI\n",
    "TrainDataDict = SyncTrainData.FilterTrainAoi(TrainDataDict)\n",
    "\n",
    "    # Create training data table\n",
    "table_df, total_samples, insufficient_df = SyncTrainData.TrainDataRaw(\n",
    "    training_data=TrainDataDict.get('training_data'),\n",
    "    landcover_df=TrainDataDict.get('landcover_df'),\n",
    "    class_field=TrainDataDict.get('class_field'))\n",
    "\n",
    "#Summary result\n",
    "vr = TrainDataDict.get('validation_results', {})\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"TRAINING DATA SUMMARY\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"Total training points loaded     : {vr.get('total_points', 'N/A')}\")\n",
    "print(f\"Points after class filtering     : {vr.get('points_after_class_filter', 'N/A')}\")\n",
    "print(f\"Valid points (inside AOI)        : {vr.get('valid_points', 'N/A')}\")\n",
    "print(f\"Invalid classes found            : {len(vr.get('invalid_classes', []))}\")\n",
    "print(f\"Points outside AOI               : {len(vr.get('outside_aoi', []))}\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "    # --- Display the main table ---\n",
    "if table_df is not None and not table_df.empty:\n",
    "        display_df = table_df.copy()\n",
    "        if 'Percentage' in display_df.columns:\n",
    "            display_df['Percentage'] = display_df['Percentage'].apply(\n",
    "                lambda x: f\"{x:.2f}%\" if isinstance(x, (int, float)) else x\n",
    "            )\n",
    "        display(display_df)\n",
    "else:\n",
    "        print(\"No valid training data available to display.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c16694e",
   "metadata": {},
   "source": [
    "## System Response 3.2 Default ROI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4869adce",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\" Loading default reference training data...\")\n",
    "TrainEePath = 'projects/ee-rg2icraf/assets/Indonesia_lulc_Sample'\n",
    "TrainField = 'kelas'\n",
    "\n",
    "# Stopgap solution: Rename 'Land Cover Class' column to 'LULC_Type' if it exists\n",
    "if 'Land Cover Class' in LULCTable.columns:\n",
    "    LULCTable = LULCTable.rename(columns={'Land Cover Class': 'LULC_Type'})\n",
    "    print(\"Column 'Land Cover Class' renamed to 'LULC_Type'\")\n",
    "\n",
    "    \n",
    "try:\n",
    "    print(\"Loading reference training data from Earth Engine...\")\n",
    "        \n",
    "        # Load training data\n",
    "    TrainDataDict = SyncTrainData.LoadTrainData(\n",
    "            landcover_df=LULCTable,\n",
    "            aoi_geometry=AOI,\n",
    "            training_ee_path=TrainEePath\n",
    "        )\n",
    "        \n",
    "    print(\"Processing and validating reference data...\")\n",
    "        \n",
    "        # Set class field\n",
    "    TrainDataDict = SyncTrainData.SetClassField(TrainDataDict, TrainField)\n",
    "        \n",
    "        # Validate classes\n",
    "    TrainDataDict = SyncTrainData.ValidClass(TrainDataDict)\n",
    "        \n",
    "        # Check sufficiency\n",
    "    TrainDataDict = SyncTrainData.CheckSufficiency(TrainDataDict, min_samples=20)\n",
    "        \n",
    "        # Filter by AOI\n",
    "    TrainDataDict = SyncTrainData.FilterTrainAoi(TrainDataDict)\n",
    "        \n",
    "        # Create summary table\n",
    "    table_df, total_samples, insufficient_df = SyncTrainData.TrainDataRaw(\n",
    "            training_data=TrainDataDict.get('training_data'),\n",
    "            landcover_df=TrainDataDict.get('landcover_df'),\n",
    "            class_field=TrainDataDict.get('class_field')\n",
    "        )\n",
    "        \n",
    "    print(\"✅ Reference training data loaded and processed successfully!\")\n",
    "    print(f\"Total samples: {total_samples}\")\n",
    "        \n",
    "        # Display summary table\n",
    "    display(table_df)\n",
    "        \n",
    "        # Store final training data\n",
    "    TrainDataFinal = TrainDataDict.get('training_data')\n",
    "        \n",
    "        # Show validation results\n",
    "    vr = TrainDataDict.get('validation_results', {})\n",
    "    print(f\"\\nValidation Results:\")\n",
    "    print(f\"- Total points loaded: {vr.get('total_points', 'N/A')}\")\n",
    "    print(f\"- Points after class filter: {vr.get('points_after_class_filter', 'N/A')}\")\n",
    "    print(f\"- Valid points (within AOI): {vr.get('valid_points', 'N/A')}\")\n",
    "    print(f\"- Invalid classes: {len(vr.get('invalid_classes', []))}\")\n",
    "        \n",
    "except Exception as e:\n",
    "        print(f\"❌ Error loading reference data: {e}\")\n",
    "        TrainDataFinal = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03d699a4",
   "metadata": {},
   "source": [
    "# Module 4: Region of Interest Separability Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5d17795",
   "metadata": {},
   "source": [
    "## Library Import and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1785681",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import the sample quality functions\n",
    "from luma_ge.sample_data_quality import sample_quality, spectral_plotter\n",
    "#if there's error in the import, uncomment the below line to install the PyCRS package\n",
    "#!pip install PyCRS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b1fdf5b",
   "metadata": {},
   "source": [
    "## System Response 4.1 Computing Separability Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fcd6b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "roi_path = '../data/Training_Sumsel_Data.shp'\n",
    "labeled_roi = geemap.shp_to_ee('../data/Training_Sumsel_Data.shp')\n",
    "# labeled_roi = geemap.gdf_to_ee(TrainDataFinal)\n",
    "\n",
    "#Conduct the analysis\n",
    "analyzer = sample_quality(training_data=labeled_roi, \n",
    "    image= stacked_landsat, \n",
    "    class_property='ID',           # Column with numeric IDs (1, 2, 3, etc.)\n",
    "    region= aoi,\n",
    "    class_name_property='LC_Name'          # Column with names ('Forest', 'Urban', 'Water', etc.)\n",
    ")\n",
    "# Extract spectral values\n",
    "pixel_extract = analyzer.extract_spectral_values(scale=100, max_pixels_per_class=5000)\n",
    "samples_statistic = analyzer.sample_stats()\n",
    "sample_df = analyzer.get_sample_stats_df()\n",
    "display(sample_df)\n",
    "#Sample statistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f87c8bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sample statistic (pixel value extracted from the imagery)\n",
    "pixel_stats = analyzer.sample_pixel_stats(pixel_extract)\n",
    "pixel_stats_df = analyzer.get_sample_pixel_stats_df(pixel_extract)\n",
    "display(pixel_stats_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb8effda",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Perform separability Analysis (iether using Transformed Divergence or Jeffries Matutista )\n",
    "separability_analysis = analyzer.get_separability_df(pixel_extract, method='TD')\n",
    "display(separability_analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4dad481",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the lowest separability\n",
    "lowest_sep = analyzer.lowest_separability(pixel_extract)\n",
    "display(lowest_sep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3347eecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overall separability summary\n",
    "sep_summary = analyzer.sum_separability(pixel_extract)\n",
    "print(\"Overall Separability Statistics:\")\n",
    "display(sep_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f8d291b",
   "metadata": {},
   "source": [
    "## System Response 4.2 Sample Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36d23c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Box plot to detect outlier\n",
    "ploter = spectral_plotter(analyzer)\n",
    "box = ploter.plot_boxplot(pixel_extract)\n",
    "for fig in box:\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5d4625e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#static scatter plot\n",
    "stat_plot = ploter.static_scatter_plot(pixel_extract, x_band='NIR', y_band='RED', add_ellipse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d21da65f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#3D scatter plot\n",
    "multi_d_scater = ploter.scatter_plot_3d(pixel_extract)\n",
    "multi_d_scater"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c4302b3",
   "metadata": {},
   "source": [
    "# Module 6: Land Cover Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6182fbfa",
   "metadata": {},
   "source": [
    "## Library Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bac11b30",
   "metadata": {},
   "outputs": [],
   "source": [
    "from luma_ge.classification import FeatureExtraction, Generate_LULC\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1da710a2",
   "metadata": {},
   "source": [
    "## System Response 6.2 Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6253ee61",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Perform Training Test Split\n",
    "features = FeatureExtraction()\n",
    "strafied_train, stratified_test = features.stratified_split(labeled_roi, stacked_landsat, \n",
    "                            class_prop='ID', train_ratio=0.5)\n",
    "classifier = Generate_LULC()\n",
    "print(\"Performing Classification...\")\n",
    "#Multiclass hard classification\n",
    "classification_map, trained_model = classifier.hard_classification(strafied_train, class_property='ID', image=stacked_landsat,\n",
    "                                                          ntrees=300, min_leaf=2, return_model=True)\n",
    "# Evaluate model performance\n",
    "print(\"Evaluating model performance...\")\n",
    "\n",
    "try:\n",
    "    accuracy_metrics = classifier.evaluate_model(\n",
    "        trained_model=trained_model,\n",
    "        test_data=stratified_test,\n",
    "        class_property='ID'\n",
    "    )\n",
    "    \n",
    "    print(\"✓ Model evaluation completed\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"❌ Error in model evaluation: {e}\")                                                    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb49859f",
   "metadata": {},
   "source": [
    "## System Response 6.3 Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "592b48ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display accuracy results\n",
    "print(\"=== Model Performance Summary ===\")\n",
    "print(f\"Overall Accuracy: {accuracy_metrics['overall_accuracy']:.4f} ({accuracy_metrics['overall_accuracy']*100:.2f}%)\")\n",
    "print(f\"Kappa Coefficient: {accuracy_metrics['kappa']:.4f}\")\n",
    "print(f\"Overall G-Mean: {accuracy_metrics['overall_gmean']:.4f}\")\n",
    "\n",
    "print(\"\\n=== Per-Class Metrics ===\")\n",
    "#Class Dataframe\n",
    "metrics_df = pd.DataFrame({\n",
    "    'Precision': accuracy_metrics['precision'],\n",
    "    'Recall': accuracy_metrics['recall'],\n",
    "    'F1-Score': accuracy_metrics['f1_scores'],\n",
    "    'G-Mean': accuracy_metrics['gmean_per_class']\n",
    "})\n",
    "\n",
    "# Round to 4 decimal places\n",
    "metrics_df = metrics_df.round(4)\n",
    "\n",
    "display(metrics_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a32e88e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize confusion matrix\n",
    "confusion_matrix = np.array(accuracy_metrics['confusion_matrix'])\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(confusion_matrix, \n",
    "            annot=True, \n",
    "            fmt='d', \n",
    "            cmap='Blues')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted Class')\n",
    "plt.ylabel('Actual Class')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f7077f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get feature importance\n",
    "print(\"Analyzing feature importance...\")\n",
    "\n",
    "try:\n",
    "    importance_df = classifier.get_feature_importance(trained_model)\n",
    "    print(\"✓ Feature importance analysis completed\")\n",
    "    \n",
    "    display(importance_df)\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"❌ Error in feature importance analysis: {e}\")\n",
    "# Visualize feature importance\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Create bar plot\n",
    "bars = plt.bar(importance_df['Band'], importance_df['Importance'])\n",
    "\n",
    "# Add value labels on bars\n",
    "for bar, value in zip(bars, importance_df['Importance']):\n",
    "    plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.5, \n",
    "             f'{value:.1f}%', ha='center', va='bottom')\n",
    "\n",
    "plt.title('Feature Importance by Spectral Band')\n",
    "plt.xlabel('Landsat 8 Bands')\n",
    "plt.ylabel('Importance')\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d8b2adb",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "536ab3fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Load Classification Scheme ===\n",
    "scheme = pd.read_csv(\"../Selected_LC_Classification_Scheme.csv\", sep=None, engine=\"python\")\n",
    "classes = [str(x).strip() for x in scheme[\"Land Cover Class\"].tolist()]\n",
    "palette = [str(x).strip() for x in scheme[\"Color Palette\"].tolist()]\n",
    "ids = scheme[\"ID\"].tolist()\n",
    "legend_dict = dict(zip(classes, palette))\n",
    "\n",
    "# === Visualization Parameters ===\n",
    "vis_params = {\n",
    "    \"min\": min(ids),\n",
    "    \"max\": max(ids),\n",
    "    \"palette\": palette\n",
    "}\n",
    "\n",
    "# === Create geemap Map ===\n",
    "Map = geemap.Map() \n",
    "Map.centerObject(aoi, 7)\n",
    "Map.addLayer(classification_map, vis_params, \"LULC Classification\")\n",
    "\n",
    "# # === Add Legend ===\n",
    "Map.add_legend(\n",
    "    title=\"Land Cover Classification\", \n",
    "    legend_dict=legend_dict\n",
    "    )\n",
    "\n",
    "# Display\n",
    "Map\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a8c0377",
   "metadata": {},
   "source": [
    "# Module 7: Thematic Accuracy Assessment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ad7a4dc",
   "metadata": {},
   "source": [
    "## System Response 7.3 Thematic Accuracy Assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9232a519",
   "metadata": {},
   "outputs": [],
   "source": [
    "from luma_ge.accuracy import Thematic_Accuracy_Assessment\n",
    "#Initialize the accuracy assessment class\n",
    "accuracy_assessor = Thematic_Accuracy_Assessment()\n",
    "print(\"✓ Thematic Accuracy Assessment class initialized\")\n",
    "print(f\"Supported metrics: {accuracy_assessor.supported_metrics}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f505ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_data = geemap.shp_to_ee(\"../data/Evaluation_Sumsel_data.shp\") \n",
    "\n",
    "# === 2. Create Assessment Object ===\n",
    "assessor = Thematic_Accuracy_Assessment()\n",
    "\n",
    "# === 3. Run Accuracy Assessment ===\n",
    "success, results = assessor.run_accuracy_assessment(\n",
    "    lcmap=classification_map,\n",
    "    validation_data=validation_data,\n",
    "    class_property='LULC_ID',   #Validation ID column\n",
    "    scale=30\n",
    ")\n",
    "\n",
    "# === 4. Display Results ===\n",
    "if success:\n",
    "    print(\"=== Thematic Accuracy Results ===\")\n",
    "    summary = assessor.format_accuracy_summary(results)\n",
    "    print(\"Overall Accuracy :\", summary['overall_accuracy'])\n",
    "    print(\"Kappa Coefficient:\", summary['kappa'])\n",
    "    print(\"95% CI          :\", summary['confidence_interval'])\n",
    "    print(\"Samples Used     :\", summary['sample_size'])\n",
    "else:\n",
    "    print(\"Error:\", results[\"error\"])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
